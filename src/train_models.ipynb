{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task and Models\n",
    "\n",
    "Our task is to focus on activity recognition, at least for now. We will create a few models to get a baseline\n",
    "\n",
    "#### Random Forest\n",
    "A random forest may be able to accurately predict activities, as this data is somewhat complex and noisy\n",
    "\n",
    "#### KNN\n",
    "K-Nearest Neighbors is likely not a good choice due to the curse of dimensionality\n",
    "\n",
    "#### Logistic/Linear Regression\n",
    "The relationships here aren't linear, so this likely wouldn't be a good choice\n",
    "\n",
    "#### Decision Trees\n",
    "These may be a good option due to the breadth of the data, but the data set is very large which may cause issues\n",
    "\n",
    "#### DNN\n",
    "Deep neural networks handle high-dimensional data well, but do not take into account sequencing. Due to this, DNNs are not a good choice\n",
    "\n",
    "#### CNN\n",
    "Convolutional neural networks are good for grid-like structures (images) and for spotting patterns in certain sectors of data. This may be a possible option, but likely wouldn't perform well. It's main use cases involve image, video, or natural language processing.\n",
    "\n",
    "#### LSTM\n",
    "Long Short-Tern Memory models are good for understanding sequential data, context, and long term dependencies. This is likely the best choice for the job (out of the deep models)\n"
   ],
   "id": "8ccad930b29cde44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:33:12.338995Z",
     "start_time": "2025-10-17T19:33:12.330844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_windows(X, y, window_size, step_size):\n",
    "    X_win, y_win = [], []\n",
    "    for i in range(0, len(X) - window_size, step_size):\n",
    "        window = X.iloc[i:i + window_size].values\n",
    "        label = y.iloc[i + window_size]\n",
    "        X_win.append(window)\n",
    "        y_win.append(label)\n",
    "    return np.array(X_win), np.array(y_win)"
   ],
   "id": "ed753237231abc93",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LSTM",
   "id": "5941a25a8aed579"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T17:03:50.787409Z",
     "start_time": "2025-10-17T17:03:50.778588Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 11,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "id": "32a42c7d1d12aa20"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T17:04:02.688976Z",
     "start_time": "2025-10-17T17:03:50.813094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "FILE_PATH = \"../processed_data/final_processed_data_ALL_DAYS.csv\"\n",
    "TARGET_COLUMN = 'activity_user_1'  # We will predict the activity for User 1\n",
    "WINDOW_SIZE = 60  # How many past time steps to look at (e.g., 60 * 2s = 120 seconds of history)\n",
    "STEP_SIZE = 30    # How far to slide the window forward each time\n",
    "\n",
    "print(\"Loading final processed data...\")\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "print(\"Separating data...\")\n",
    "df.dropna(inplace=True)\n",
    "X = df.drop(columns=[col for col in df.columns if 'activity' in col])\n",
    "y = df[TARGET_COLUMN].astype(int)\n",
    "num_classes = len(y.unique())\n",
    "y_categorical = to_categorical(y, num_classes=num_classes)\n",
    "print(f\"Creating sliding windows (size={WINDOW_SIZE}, step={STEP_SIZE})...\")\n",
    "X_win, y_win = create_windows(X, pd.Series(y_categorical.tolist()), WINDOW_SIZE, STEP_SIZE)\n",
    "print(f\"  - Windowed X shape: {X_win.shape}\")\n",
    "print(f\"  - Windowed y shape: {y_win.shape}\")\n",
    "\n",
    "print(\"Splitting data into training and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_win, y_win, test_size=0.2, random_state=42)\n",
    "print(f\"  - Training set size: {len(X_train)}\")\n",
    "print(f\"  - Test set size: {len(X_test)}\")\n",
    "\n",
    "print(\"Building the LSTM model...\")\n",
    "model = Sequential([\n",
    "    # The input layer must match the shape of our windows (WINDOW_SIZE, num_features)\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(64),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax') # The output layer has one neuron per activity\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nTraining the model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,          # Start with a few epochs to see how it goes\n",
    "    batch_size=128,\n",
    "    validation_split=0.1, # Use part of the training data for validation\n",
    "    verbose=1\n",
    ")\n",
    "model.save('LSTM_first_iteration.keras')\n",
    "\n",
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred))"
   ],
   "id": "1b08abd3e756a717",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading final processed data...\n",
      "Separating data...\n",
      "Creating sliding windows (size=60, step=30)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 26\u001B[39m\n\u001B[32m     24\u001B[39m y_categorical = to_categorical(y, num_classes=num_classes)\n\u001B[32m     25\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCreating sliding windows (size=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mWINDOW_SIZE\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, step=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSTEP_SIZE\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m X_win, y_win = \u001B[43mcreate_windows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_categorical\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mWINDOW_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSTEP_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  - Windowed X shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mX_win.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  - Windowed y shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_win.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36mcreate_windows\u001B[39m\u001B[34m(X, y, window_size, step_size)\u001B[39m\n\u001B[32m      2\u001B[39m X_win, y_win = [], []\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(X) - window_size, step_size):\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     window = \u001B[43mX\u001B[49m\u001B[43m.\u001B[49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m:\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindow_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\n\u001B[32m      5\u001B[39m     label = y.iloc[i + window_size]\n\u001B[32m      6\u001B[39m     X_win.append(window)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:12671\u001B[39m, in \u001B[36mDataFrame.values\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m  12597\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m  12598\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> np.ndarray:\n\u001B[32m  12599\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m  12600\u001B[39m \u001B[33;03m    Return a Numpy representation of the DataFrame.\u001B[39;00m\n\u001B[32m  12601\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m  12669\u001B[39m \u001B[33;03m           ['monkey', nan, None]], dtype=object)\u001B[39;00m\n\u001B[32m  12670\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m> \u001B[39m\u001B[32m12671\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_mgr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mas_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001B[39m, in \u001B[36mBlockManager.as_array\u001B[39m\u001B[34m(self, dtype, copy, na_value)\u001B[39m\n\u001B[32m   1692\u001B[39m         arr.flags.writeable = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   1693\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1694\u001B[39m     arr = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_interleave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_value\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m     \u001B[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001B[39;00m\n\u001B[32m   1696\u001B[39m     \u001B[38;5;66;03m# to further copy if copy=True or setting na_value\u001B[39;00m\n\u001B[32m   1698\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_value \u001B[38;5;129;01mis\u001B[39;00m lib.no_default:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1754\u001B[39m, in \u001B[36mBlockManager._interleave\u001B[39m\u001B[34m(self, dtype, na_value)\u001B[39m\n\u001B[32m   1752\u001B[39m         arr = blk.get_values(dtype)\n\u001B[32m   1753\u001B[39m     result[rl.indexer] = arr\n\u001B[32m-> \u001B[39m\u001B[32m1754\u001B[39m     itemmask[rl.indexer] = \u001B[32m1\u001B[39m\n\u001B[32m   1756\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m itemmask.all():\n\u001B[32m   1757\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mSome items were not contained in blocks\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest",
   "id": "18417738047d4b15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:25:16.026243Z",
     "start_time": "2025-10-17T19:24:31.031066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "FILE_PATH = \"../processed_data/final_processed_data_ALL_DAYS.csv\"\n",
    "TARGET_COLUMN = 'activity_user_1'\n",
    "WINDOW_SIZE = 60  # 120 seconds of history\n",
    "STEP_SIZE = 30\n",
    "\n",
    "print(\"Loading final processed data...\")\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "print(\"Separating Features and Target...\")\n",
    "df.dropna(inplace=True)\n",
    "X = df.drop(columns=[col for col in df.columns if 'activity' in col])\n",
    "y = df[TARGET_COLUMN].astype(int)\n",
    "\n",
    "print(f\"Creating sliding windows (size={WINDOW_SIZE}, step={STEP_SIZE})...\")\n",
    "X_win, y_win = create_windows(X, y, WINDOW_SIZE, STEP_SIZE)\n",
    "print(f\"  - Initial windowed X shape: {X_win.shape}\")\n",
    "\n",
    "print(\"Flattening window data...\")\n",
    "n_samples, n_timesteps, n_features = X_win.shape\n",
    "X_flattened = X_win.reshape((n_samples, n_timesteps * n_features))\n",
    "print(f\"  - Flattened X shape: {X_flattened.shape}\")\n",
    "\n",
    "print(\"Splitting data into training and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flattened, y_win, test_size=0.2, random_state=42)\n",
    "print(f\"  - Training set size: {len(X_train)}\")\n",
    "print(f\"  - Test set size: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nBuilding and training the Random Forest model...\")\n",
    "# n_estimators is the number of trees in the forest.\n",
    "# n_jobs=-1 uses all available CPU cores for faster training.\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "joblib.dump(model, \"../models/RandomForest_first_iteration.joblib\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "# You may need to create a mapping from integer back to activity name for readability\n",
    "activity_names = [\"BATHROOM ACTIVITY\", \"CHORES\", \"COOK\", \"DISHWASHING\", \"DRESS\", \"EAT\", \"LAUNDRY\",\n",
    "                  \"MAKE SIMPLE FOOD\", \"OUT HOME\", \"PET\", \"READ\", \"RELAX\", \"SHOWER\", \"SLEEP\",\n",
    "                  \"TAKE MEDS\", \"WATCH TV\", \"WORK\", \"OTHER\"]\n",
    "print(classification_report(y_test, y_pred, target_names=activity_names))"
   ],
   "id": "5bb8c0c59a5ea06f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading final processed data...\n",
      "Separating Features and Target...\n",
      "Creating sliding windows (size=60, step=30)...\n",
      "  - Initial windowed X shape: (67467, 60, 41)\n",
      "Flattening window data...\n",
      "  - Flattened X shape: (67467, 2460)\n",
      "Splitting data into training and test sets...\n",
      "  - Training set size: 53973\n",
      "  - Test set size: 13494\n",
      "\n",
      "Building and training the Random Forest model...\n",
      "\n",
      "Evaluating the model on the test set...\n",
      "\n",
      "Test Accuracy: 97.90%\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "BATHROOM ACTIVITY       0.94      0.92      0.93       381\n",
      "           CHORES       0.99      0.88      0.93        83\n",
      "             COOK       0.96      0.89      0.93       139\n",
      "      DISHWASHING       1.00      0.88      0.93        16\n",
      "            DRESS       0.75      0.36      0.49        33\n",
      "              EAT       0.92      0.98      0.95       609\n",
      "          LAUNDRY       0.00      0.00      0.00         1\n",
      " MAKE SIMPLE FOOD       0.93      0.72      0.81       104\n",
      "         OUT HOME       1.00      1.00      1.00      5246\n",
      "              PET       0.50      0.13      0.21        15\n",
      "             READ       0.92      0.98      0.95       177\n",
      "            RELAX       0.93      0.89      0.91       148\n",
      "           SHOWER       0.98      0.95      0.96        84\n",
      "            SLEEP       1.00      1.00      1.00      4290\n",
      "        TAKE MEDS       0.33      0.50      0.40         6\n",
      "         WATCH TV       0.98      0.98      0.98      1114\n",
      "             WORK       0.97      0.99      0.98       304\n",
      "            OTHER       0.87      0.91      0.89       744\n",
      "\n",
      "         accuracy                           0.98     13494\n",
      "        macro avg       0.83      0.77      0.79     13494\n",
      "     weighted avg       0.98      0.98      0.98     13494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesse\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jesse\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jesse\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Decision Tree",
   "id": "abce6471c265de27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:30:26.825351Z",
     "start_time": "2025-10-17T19:29:21.258087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "FILE_PATH = \"../processed_data/final_processed_data_ALL_DAYS.csv\"\n",
    "TARGET_COLUMN = 'activity_user_1'\n",
    "WINDOW_SIZE = 60\n",
    "STEP_SIZE = 30\n",
    "\n",
    "print(\"Loading final processed data...\")\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "print(\"Separating Features and Target...\")\n",
    "df.dropna(inplace=True)\n",
    "X = df.drop(columns=[col for col in df.columns if 'activity' in col])\n",
    "y = df[TARGET_COLUMN].astype(int)\n",
    "\n",
    "print(f\"Creating sliding windows (size={WINDOW_SIZE}, step={STEP_SIZE})...\")\n",
    "X_win, y_win = create_windows(X, y, WINDOW_SIZE, STEP_SIZE)\n",
    "print(f\"  - Initial windowed X shape: {X_win.shape}\")\n",
    "\n",
    "print(\"Flattening window data...\")\n",
    "n_samples, n_timesteps, n_features = X_win.shape\n",
    "X_flattened = X_win.reshape((n_samples, n_timesteps * n_features))\n",
    "print(f\"  - Flattened X shape: {X_flattened.shape}\")\n",
    "\n",
    "print(\"Splitting data into training and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flattened, y_win, test_size=0.2, random_state=42)\n",
    "print(f\"  - Training set size: {len(X_train)}\")\n",
    "print(f\"  - Test set size: {len(X_test)}\")\n",
    "\n",
    "print(\"Building and training the Decision Tree model...\")\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"  - Model training complete!\")\n",
    "\n",
    "print(\"Evaluating the model on the test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "activity_names = [\"BATHROOM ACTIVITY\", \"CHORES\", \"COOK\", \"DISHWASHING\", \"DRESS\", \"EAT\", \"LAUNDRY\",\n",
    "                  \"MAKE SIMPLE FOOD\", \"OUT HOME\", \"PET\", \"READ\", \"RELAX\", \"SHOWER\", \"SLEEP\",\n",
    "                  \"TAKE MEDS\", \"WATCH TV\", \"WORK\", \"OTHER\"]\n",
    "print(classification_report(y_test, y_pred, target_names=activity_names))\n",
    "\n",
    "print(\"Saving the Decision Tree model...\")\n",
    "joblib.dump(model, \"../models/DecisionTree_first_iteration.joblib\")\n",
    "print(\"  - Model saved successfully!\")"
   ],
   "id": "88be93a52bf04f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading final processed data...\n",
      "Separating Features and Target...\n",
      "Creating sliding windows (size=60, step=30)...\n",
      "  - Initial windowed X shape: (67467, 60, 41)\n",
      "Flattening window data...\n",
      "  - Flattened X shape: (67467, 2460)\n",
      "Splitting data into training and test sets...\n",
      "  - Training set size: 53973\n",
      "  - Test set size: 13494\n",
      "Building and training the Decision Tree model...\n",
      "  - Model training complete!\n",
      "Evaluating the model on the test set...\n",
      "\n",
      "Test Accuracy: 95.90%\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "BATHROOM ACTIVITY       0.90      0.89      0.89       381\n",
      "           CHORES       0.81      0.78      0.80        83\n",
      "             COOK       0.81      0.78      0.80       139\n",
      "      DISHWASHING       0.82      0.56      0.67        16\n",
      "            DRESS       0.23      0.24      0.24        33\n",
      "              EAT       0.88      0.90      0.89       609\n",
      "          LAUNDRY       0.00      0.00      0.00         1\n",
      " MAKE SIMPLE FOOD       0.70      0.64      0.67       104\n",
      "         OUT HOME       1.00      1.00      1.00      5246\n",
      "              PET       0.21      0.27      0.24        15\n",
      "             READ       0.88      0.88      0.88       177\n",
      "            RELAX       0.77      0.80      0.78       148\n",
      "           SHOWER       0.92      0.94      0.93        84\n",
      "            SLEEP       0.99      0.99      0.99      4290\n",
      "        TAKE MEDS       0.17      0.17      0.17         6\n",
      "         WATCH TV       0.96      0.95      0.96      1114\n",
      "             WORK       0.90      0.94      0.92       304\n",
      "            OTHER       0.82      0.81      0.81       744\n",
      "\n",
      "         accuracy                           0.96     13494\n",
      "        macro avg       0.71      0.70      0.70     13494\n",
      "     weighted avg       0.96      0.96      0.96     13494\n",
      "\n",
      "Saving the Decision Tree model...\n",
      "  - Model saved successfully!\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
